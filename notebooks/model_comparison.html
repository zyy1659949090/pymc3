
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Model comparison &#8212; PyMC3 3.2 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model averaging" href="model_averaging.html" />
    <link rel="prev" title="Posterior Predictive Checks" href="posterior_predictive.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }
</style>
<div class="section" id="Model-comparison">
<h1>Model comparison<a class="headerlink" href="#Model-comparison" title="Permalink to this headline">¶</a></h1>
<p>To demonstrate the use of model comparison criteria in PyMC3, we
implement the <strong>8 schools</strong> example from Section 5.5 of Gelman et al
(2003), which attempts to infer the effects of coaching on SAT scores of
students from 8 schools. Below, we fit a <strong>pooled model</strong>, which assumes
a single fixed effect across all schools, and a <strong>hierarchical model</strong>
that allows for a random effect that partially pools the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;notebook&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The data include the observed treatment effects and associated standard
deviations in the 8 schools.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">J</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">28</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="Pooled-model">
<h2>Pooled model<a class="headerlink" href="#Pooled-model" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pooled</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mf">1e6</span><span class="p">)</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="n">trace_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using ADVI...
Average Loss = 43.342:   4%|▍         | 7754/200000 [00:00&lt;00:12, 14950.83it/s]
Convergence archived at 9400
Interrupted at 9,400 [4%]: Average Loss = 43.902
100%|██████████| 1500/1500 [00:00&lt;00:00, 2870.72it/s]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace_p</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_model_comparison_6_0.png" src="../_images/notebooks_model_comparison_6_0.png" />
</div>
</div>
</div>
<div class="section" id="Hierarchical-model">
<h2>Hierarchical model<a class="headerlink" href="#Hierarchical-model" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical</span><span class="p">:</span>

    <span class="n">eta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;eta&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">J</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mf">1e6</span><span class="p">)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;tau&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">tau</span><span class="o">*</span><span class="n">eta</span><span class="p">)</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;obs&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="n">trace_h</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using ADVI...
Average Loss = 43.29:  11%|█▏        | 22935/200000 [00:02&lt;00:14, 12516.51it/s]
Convergence archived at 23000
Interrupted at 23,000 [11%]: Average Loss = 44.107
 94%|█████████▍| 1412/1500 [00:01&lt;00:00, 1234.30it/s]/Users/fonnescj/Repos/pymc3/pymc3/step_methods/hmc/nuts.py:456: UserWarning: Chain 0 contains 1 diverging samples after tuning. If increasing `target_accept` does not help try to reparameterize.
  % (self._chain_id, n_diverging))
100%|██████████| 1500/1500 [00:01&lt;00:00, 1162.34it/s]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_model_comparison_9_0.png" src="../_images/notebooks_model_comparison_9_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">forestplot</span><span class="p">(</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_model_comparison_10_0.png" src="../_images/notebooks_model_comparison_10_0.png" />
</div>
</div>
</div>
<div class="section" id="Deviance-Information-Criterion-(DIC)">
<h2>Deviance Information Criterion (DIC)<a class="headerlink" href="#Deviance-Information-Criterion-(DIC)" title="Permalink to this headline">¶</a></h2>
<p>DIC (Spiegelhalter et al. 2002) is an information theoretic criterion
for estimating predictive accuracy that is analogous to Akaike’s
Information Criterion (AIC). It is a more Bayesian approach that allows
for the modeling of random effects, replacing the maximum likelihood
estimate with the posterior mean and using the effective number of
parameters to correct for bias.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pooled_dic</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">dic</span><span class="p">(</span><span class="n">trace_p</span><span class="p">,</span> <span class="n">pooled</span><span class="p">)</span>

<span class="n">pooled_dic</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[8]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>90.882480923881175
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">hierarchical_dic</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">dic</span><span class="p">(</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">hierarchical</span><span class="p">)</span>

<span class="n">hierarchical_dic</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[9]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>124.2888830531669
</pre></div>
</div>
</div>
</div>
<div class="section" id="Widely-applicable-Information-Criterion-(WAIC)">
<h2>Widely-applicable Information Criterion (WAIC)<a class="headerlink" href="#Widely-applicable-Information-Criterion-(WAIC)" title="Permalink to this headline">¶</a></h2>
<p>WAIC (Watanabe 2010) is a fully Bayesian criterion for estimating
out-of-sample expectation, using the computed log pointwise posterior
predictive density (LPPD) and correcting for the effective number of
parameters to adjust for overfitting.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pooled_waic</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">waic</span><span class="p">(</span><span class="n">trace_p</span><span class="p">,</span> <span class="n">pooled</span><span class="p">)</span>

<span class="n">pooled_waic</span><span class="o">.</span><span class="n">WAIC</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[10]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>61.136455281870752
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">hierarchical_waic</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">waic</span><span class="p">(</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">hierarchical</span><span class="p">)</span>

<span class="n">hierarchical_waic</span><span class="o">.</span><span class="n">WAIC</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[11]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>61.350518836043364
</pre></div>
</div>
</div>
<p>PyMC3 includes two convenience functions to help compare WAIC for
different models. The first of this functions is <code class="docutils literal"><span class="pre">compare</span></code>, this one
computes WAIC (or LOO) from a set of traces and models and returns a
DataFrame.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">df_comp_WAIC</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">compare</span><span class="p">((</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">trace_p</span><span class="p">),</span> <span class="p">(</span><span class="n">hierarchical</span><span class="p">,</span> <span class="n">pooled</span><span class="p">))</span>
<span class="n">df_comp_WAIC</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>WAIC</th>
      <th>pWAIC</th>
      <th>dWAIC</th>
      <th>weight</th>
      <th>SE</th>
      <th>dSE</th>
      <th>warning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>61.1365</td>
      <td>0.676001</td>
      <td>0</td>
      <td>0.526732</td>
      <td>2.20685</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>61.3505</td>
      <td>0.985125</td>
      <td>0.214064</td>
      <td>0.473268</td>
      <td>1.94631</td>
      <td>0.0389335</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We have many columns so let check one by one the meaning of them:</p>
<ol class="arabic simple">
<li>The first column clearly contains the values of WAIC. The DataFrame
is always sorted from lowest to highest WAIC. The index reflects the
order in which the models are passed to this function.</li>
<li>The second column is the estimated effective number of parameters. In
general, models with more parameters will be more flexible to fit
data and at the same time could also lead to overfitting. Thus we can
interpret pWAIC as a penalization term, intuitively we can also
interpret it as measure of how flexible each model is in fitting the
data.</li>
<li>The third column is the relative difference between the value of WAIC
for the top-ranked model and the value of WAIC for each model. For
this reason we will always get a value of 0 for the first model.</li>
<li>Sometimes when comparing models, we do not want to select the “best”
model, instead we want to perform predictions by averaging along all
the models (or at least several models). Ideally we would like to
perform a weighted average, giving more weight to the model that
seems to explain/predict the data better. There are many approaches
to perform this task, one of them is to use Akaike weights based on
the values of WAIC for each model. These weights can be loosely
interpreted as the probability of each model (among the compared
models) given the data. One caveat of this approach is that the
weights are based on point estimates of WAIC (i.e. the uncertainty is
ignored).</li>
<li>The fifth column records the standard error for the WAIC
computations. The standard error can be useful to assess the
uncertainty of the WAIC estimates. Nevertheless, caution need to be
taken because the estimation of the standard error assumes normality
and hence could be problematic when the sample size is low.</li>
<li>In the same way that we can compute the standard error for each value
of WAIC, we can compute the standard error of the differences between
two values of WAIC. Notice that both quantities are not necessarily
the same, the reason is that the uncertainty about WAIC is correlated
between models. This quantity is always 0 for the top-ranked model.</li>
<li>Finally we have the last column named “warning”. A value of 1
indicates that the computation of WAIC may not be reliable, this
warning is based on an empirical determined cutoff value and need to
be interpreted with caution. For more details you can read this
<a class="reference external" href="https://arxiv.org/abs/1507.04544">paper</a>.</li>
</ol>
<p>The second convenience function takes the output of <code class="docutils literal"><span class="pre">compare</span></code> and
produces a summary plot in the style of the one used in the book
<a class="reference external" href="http://xcelab.net/rm/statistical-rethinking/">Statistical
Rethinking</a> by Richard
McElreath (check also <a class="reference external" href="https://github.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3">this
port</a>
of the examples in the book to PyMC3).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">compareplot</span><span class="p">(</span><span class="n">df_comp_WAIC</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_model_comparison_21_0.png" src="../_images/notebooks_model_comparison_21_0.png" />
</div>
</div>
<p>The empty circle represents the values of WAIC and the black error bars
associated with them are the values of the standard deviation of WAIC.</p>
<p>The value of the lowest WAIC is also indicated with a vertical dashed
grey line to ease comparison with other WAIC values.</p>
<p>The filled black dots are the in-sample deviance of each model, which
for WAIC is 2 pWAIC from the corresponding WAIC value.</p>
<p>For all models except the top-ranked one we also get a triangle
indicating the value of the difference of WAIC between that model and
the top model and a grey errobar indicating the standard error of the
differences between the top-ranked WAIC and WAIC for each model.</p>
</div>
<div class="section" id="Leave-one-out-Cross-validation-(LOO)">
<h2>Leave-one-out Cross-validation (LOO)<a class="headerlink" href="#Leave-one-out-Cross-validation-(LOO)" title="Permalink to this headline">¶</a></h2>
<p>LOO cross-validation is an estimate of the out-of-sample predictive fit.
In cross-validation, the data are repeatedly partitioned into training
and holdout sets, iteratively fitting the model with the former and
evaluating the fit with the holdout data. Vehtari et al. (2016)
introduced an efficient computation of LOO from MCMC samples, which are
corrected using Pareto-smoothed importance sampling (PSIS) to provide an
estimate of point-wise out-of-sample prediction accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pooled_loo</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">loo</span><span class="p">(</span><span class="n">trace_p</span><span class="p">,</span> <span class="n">pooled</span><span class="p">)</span>

<span class="n">pooled_loo</span><span class="o">.</span><span class="n">LOO</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/Users/fonnescj/Repos/pymc3/pymc3/stats.py:255: UserWarning: Estimated shape parameter of Pareto distribution is
        greater than 0.7 for one or more samples.
        You should consider using a more robust model, this is
        because importance sampling is less likely to work well if the marginal
        posterior and LOO posterior are very different. This is more likely to
        happen with a non-robust model and highly influential observations.
  happen with a non-robust model and highly influential observations.&#34;&#34;&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[15]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>61.555247474354104
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">hierarchical_loo</span>  <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">loo</span><span class="p">(</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">hierarchical</span><span class="p">)</span>

<span class="n">hierarchical_loo</span><span class="o">.</span><span class="n">LOO</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/Users/fonnescj/Repos/pymc3/pymc3/stats.py:255: UserWarning: Estimated shape parameter of Pareto distribution is
        greater than 0.7 for one or more samples.
        You should consider using a more robust model, this is
        because importance sampling is less likely to work well if the marginal
        posterior and LOO posterior are very different. This is more likely to
        happen with a non-robust model and highly influential observations.
  happen with a non-robust model and highly influential observations.&#34;&#34;&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[16]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>61.413990925656876
</pre></div>
</div>
</div>
<p>We can also use <code class="docutils literal"><span class="pre">compare</span></code> with LOO.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">df_comp_LOO</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">compare</span><span class="p">((</span><span class="n">trace_h</span><span class="p">,</span> <span class="n">trace_p</span><span class="p">),</span> <span class="p">(</span><span class="n">hierarchical</span><span class="p">,</span> <span class="n">pooled</span><span class="p">),</span> <span class="n">ic</span><span class="o">=</span><span class="s1">&#39;LOO&#39;</span><span class="p">)</span>
<span class="n">df_comp_LOO</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LOO</th>
      <th>pLOO</th>
      <th>dLOO</th>
      <th>weight</th>
      <th>SE</th>
      <th>dSE</th>
      <th>warning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>61.414</td>
      <td>1.01686</td>
      <td>0</td>
      <td>0.51765</td>
      <td>1.95466</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>61.5552</td>
      <td>0.885397</td>
      <td>0.141257</td>
      <td>0.48235</td>
      <td>2.1805</td>
      <td>0.0347903</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The columns return the equivalent values for LOO, notice that in this
example we get two warnings. Also notice that the order of the models is
not the same as the one for WAIC.</p>
<p>We can also plot the results</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">compareplot</span><span class="p">(</span><span class="n">df_comp_LOO</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_model_comparison_29_0.png" src="../_images/notebooks_model_comparison_29_0.png" />
</div>
</div>
</div>
<div class="section" id="Interpretation">
<h2>Interpretation<a class="headerlink" href="#Interpretation" title="Permalink to this headline">¶</a></h2>
<p>Though we might expect the hierarchical model to outperform a complete
pooling model, there is little to choose between the models in this
case, giving that both models gives very similar values of the
information criteria. This is more clearly appreciated when we take into
account the uncertainty (in terms of standard errors) of WAIC and LOO.</p>
<div class="section" id="Reference">
<h3>Reference<a class="headerlink" href="#Reference" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://doi.org/10.1007/s11222-013-9416-2">Gelman, A., Hwang, J., &amp; Vehtari, A. (2014). Understanding predictive
information criteria for Bayesian models. Statistics and Computing,
24(6), 997–1016.</a></p>
<p><a class="reference external" href="http://link.springer.com/article/10.1007/s11222-016-9696-4">Vehtari, A, Gelman, A, Gabry, J. (2016). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC. Statistics and
Computing</a></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/pymc3_logo.jpg" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">PyMC3</a></h1>



<p class="blurb">Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with Theano</p>






<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prob_dists.html">Probability Distributions</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../examples.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../examples.html#howto">Howto</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sampler-stats.html">Sampler statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="Diagnosing_biased_Inference_with_Divergences.html">Diagnosing Biased Inference with Divergences</a></li>
<li class="toctree-l3"><a class="reference internal" href="posterior_predictive.html">Posterior Predictive Checks</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Model comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_averaging.html">Model averaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="Bayes_factor.html">Bayes Factors and Marginal Likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="howto_debugging.html">How to debug a model</a></li>
<li class="toctree-l3"><a class="reference internal" href="PyMC3_tips_and_heuristic.html">PyMC3 Modeling tips and heuristic</a></li>
<li class="toctree-l3"><a class="reference internal" href="LKJ.html">LKJ Cholesky Covariance Priors for Multivariate Normal Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="live_sample_plots.html">Live sample plots</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#applied">Applied</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#glm">GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#gaussian-processes">Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#mixture-models">Mixture Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#variational-inference">Variational Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, The PyMC Development Team.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/notebooks/model_comparison.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>